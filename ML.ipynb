{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f8027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torchvision functions\n",
    "import torchvision\n",
    "from torchvision.models import vgg16\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# import other functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "from itertools import islice\n",
    "from PIL import Image\n",
    "import time \n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d57285",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = r'C:\\Users\\pauli\\Documents\\M2\\ML et DL\\projet\\Git\\DamageDetection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907b809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_damage_dir = original_dataset_dir + '/train_another/damage'\n",
    "validation_damage_dir = original_dataset_dir + '/validation_another/damage'\n",
    "test_damage_dir = original_dataset_dir + '/test/damage'\n",
    "\n",
    "train_nodamage_dir = original_dataset_dir + '/train_another/no_damage'\n",
    "validation_nodamage_dir = original_dataset_dir + '/validation_another/no_damage'\n",
    "test_nodamage_dir = original_dataset_dir + '/test/no_damage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3847ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training damage images:  5000\n",
      "total validation damage images:  1000\n",
      "total test damage images:  1000\n",
      "total training no damage images:  5000\n",
      "total validation no damage images:  1000\n",
      "total test no damage images:  1000\n"
     ]
    }
   ],
   "source": [
    "print('total training damage images: ',len(os.listdir(train_damage_dir)))\n",
    "print('total validation damage images: ',len(os.listdir(validation_damage_dir)))\n",
    "print('total test damage images: ',len(os.listdir(test_damage_dir)))\n",
    "\n",
    "print('total training no damage images: ',len(os.listdir(train_nodamage_dir)))\n",
    "print('total validation no damage images: ',len(os.listdir(validation_nodamage_dir)))\n",
    "print('total test no damage images: ',len(os.listdir(test_nodamage_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fe3aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour entrainer les modeles\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, steps_per_epoch, validation_steps):\n",
    "    epoch_nums = []\n",
    "    training_acc = []\n",
    "    validation_acc = []\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        accuracy = 0.0\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        # Entraîne le modèle sur les données d'entraînement\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            print(images)\n",
    "            # Entraîne le modèle sur un lot de données\n",
    "            outputs = model(images)\n",
    "            print(outputs)\n",
    "            loss = criterion(outputs, labels.float().view(-1,1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #running_loss += loss.item()\n",
    "            accuracy += (torch.round(outputs) == labels.float().view(-1,1)).sum().item() / len(labels)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            if (i+1) % steps_per_epoch == 0:\n",
    "                break\n",
    "        train_loss = running_loss / steps_per_epoch\n",
    "        train_acc = accuracy / steps_per_epoch \n",
    "                \n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_acc = 0\n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels.float().view(-1,1)).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_acc += (torch.round(outputs) == labels.float().view(-1,1)).sum().item() / len(labels)\n",
    "                \n",
    "                if i >= validation_steps:\n",
    "                    break\n",
    "        \n",
    "        val_loss /= validation_steps\n",
    "        val_acc /= validation_steps \n",
    "\n",
    "        epoch_nums.append(epoch+1)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(val_loss)\n",
    "        training_acc.append(train_acc)\n",
    "        validation_acc.append(val_acc)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(elapsed_time)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Time : {elapsed_time:.4f}, Train Loss: {loss.item():.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "    return {\n",
    "        'training_acc': training_acc,\n",
    "        'validation_acc': validation_acc,\n",
    "        'training_loss': training_loss,\n",
    "        'validation_loss': validation_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f094b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-17          [-1, 256, 18, 18]               0\n",
      "           Conv2d-18          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-19          [-1, 512, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-24            [-1, 512, 9, 9]               0\n",
      "           Conv2d-25            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-26            [-1, 512, 9, 9]               0\n",
      "           Conv2d-27            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "        MaxPool2d-31            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 96.93\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 624.98\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-17          [-1, 256, 18, 18]               0\n",
      "           Conv2d-18          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-19          [-1, 512, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-24            [-1, 512, 9, 9]               0\n",
      "           Conv2d-25            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-26            [-1, 512, 9, 9]               0\n",
      "           Conv2d-27            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 96.49\n",
      "Params size (MB): 56.13\n",
      "Estimated Total Size (MB): 152.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Chargment du modèle pré-entraîné ResNet18\n",
    "modelvgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "torchsummary.summary(modelvgg16, (3,150,150))\n",
    "\n",
    "# Extraction des caractéristiques\n",
    "modelvgg16 = modelvgg16.features[:-1] # nombre de caractéristiques en entrée de la couche fc\n",
    "torchsummary.summary(modelvgg16, (3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd23638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    #transforms.Normalize((0,), (1/255,))\n",
    "])\n",
    "\n",
    "batch_size=20\n",
    "\n",
    "train_dataset = ImageFolder(r'C:\\Users\\pauli\\Documents\\M2\\ML et DL\\projet\\Git\\DamageDetection\\train_another', transform=datagen)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "val_dataset = ImageFolder(r'C:\\Users\\pauli\\Documents\\M2\\ML et DL\\projet\\Git\\DamageDetection\\validation_another', transform=datagen)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder(r'C:\\Users\\pauli\\Documents\\M2\\ML et DL\\projet\\Git\\DamageDetection\\test_another', transform=datagen)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "\n",
    "modelvgg16.eval()\n",
    "\n",
    "# Extraire les caractéristiques des images\n",
    "def extract_features(data_loader, sample_count, conv_base, batch_size):\n",
    "    features = torch.zeros(sample_count, 512, 9, 9)\n",
    "    labels = torch.zeros(sample_count, dtype=torch.long)\n",
    "    \n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in data_loader:\n",
    "        with torch.no_grad():\n",
    "            features_batch = conv_base(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f00c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features(train_loader, 10000, modelvgg16, batch_size=batch_size)\n",
    "validation_features, validation_labels = extract_features(val_loader, 2000, modelvgg16, batch_size=batch_size)\n",
    "test_features, test_labels = extract_features(test_loader, 2000, modelvgg16, batch_size=batch_size)\n",
    "\n",
    "# Reformater les caractéristiques pour être de forme (sample_count, 8192)\n",
    "train_features = train_features.view(10000, 9 * 9 * 512)\n",
    "validation_features = validation_features.view(2000, 9 * 9 * 512)\n",
    "test_features = test_features.view(2000, 9 * 9 * 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0f08943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_features, train_labels, val_features, validation_labels, num_epochs, batch_size):\n",
    "    train_features = train_features.float()\n",
    "    train_labels = train_labels.long()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_features)\n",
    "        loss = criterion(outputs, train_labels.float().view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Valider le modèle\n",
    "        with torch.no_grad():\n",
    "            validation_outputs = model(validation_features.float())\n",
    "            _, validation_predicted = torch.max(validation_outputs, 1)\n",
    "            validation_correct = (validation_predicted == validation_labels.long()).sum().item()\n",
    "            validation_accuracy = validation_correct / validation_labels.shape[0]\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, Validation Accuracy: {:.2f}%'.format(epoch + 1, num_epochs, loss.item(), validation_accuracy * 100))\n",
    "        \n",
    "        \n",
    "def evaluate(model, test_feature, test_labels):\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_features.float())\n",
    "        _, test_predicted = torch.max(test_outputs, 1)\n",
    "        test_correct = (test_predicted == test_labels.long()).sum().item()\n",
    "        test_accuracy = test_correct / test_labels.shape[0]\n",
    "        print('Test Accuracy: {:.2f}%'.format(test_accuracy * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f910eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(9 * 9 * 512, 256) \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "BinaryClassifier = BinaryClassifier()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.RMSprop(BinaryClassifier.parameters(), lr=0.0001)\n",
    "\n",
    "#train(BinaryClassifier, train_features, train_labels, validation_features, validation_labels, 10, 20)\n",
    "\n",
    "#BinaryClassifier.evaluate(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d4707c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9532\\3761913829.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Lancer l'entraînement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBinaryClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9532\\3362008043.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, train_loader, val_loader, epochs, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Entraîne le modèle sur les données d'entraînement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m# Entraîne le modèle sur un lot de données\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Initialisation des paramètres \n",
    "steps_per_epoch = 100\n",
    "epochs = 30\n",
    "validation_steps = 50\n",
    "\n",
    "# Lancer l'entraînement\n",
    "history = fit(BinaryClassifier, train_features, validation_features, epochs, steps_per_epoch, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a906a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pattal\\.conda\\envs\\DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc =  0.9365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression(C = 1)\n",
    "logisticRegr.fit(train_features,train_labels)\n",
    "#balanced test set \n",
    "score1 = logisticRegr.score(validation_features, validation_labels)\n",
    "print(\"Validation acc = \", score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b1a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a72cdb8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Évaluation du modèle\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 6\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m model_load(\u001b[43mtest_features\u001b[49m)\n\u001b[0;32m      7\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()(test_outputs, test_labels)\n\u001b[0;32m      8\u001b[0m     test_results \u001b[38;5;241m=\u001b[39m (test_loss, test_outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39meq(test_labels)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Chargement du modèle\n",
    "model_load = model\n",
    "\n",
    "# Évaluation du modèle\n",
    "with torch.no_grad():\n",
    "    test_outputs = model_load(test_features)\n",
    "    test_loss = nn.BCELoss()(test_outputs, test_labels)\n",
    "    test_results = (test_loss, test_outputs.argmax(dim=1).eq(test_labels).float().mean().item())\n",
    "    print(test_results)\n",
    "\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size, C=1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b06448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb7edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
