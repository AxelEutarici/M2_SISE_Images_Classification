{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f8027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torchvision functions\n",
    "import torchvision\n",
    "from torchvision.models import vgg16\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "# import other functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d57285",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = 'C:/Users/pauli/Documents/M2/ML et DL/projet/Git/DamageDetection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907b809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_damage_dir = original_dataset_dir + '/train_another/damage'\n",
    "validation_damage_dir = original_dataset_dir + '/validation_another/damage'\n",
    "test_damage_dir = original_dataset_dir + '/test/damage'\n",
    "\n",
    "train_nodamage_dir = original_dataset_dir + '/train_another/no_damage'\n",
    "validation_nodamage_dir = original_dataset_dir + '/validation_another/no_damage'\n",
    "test_nodamage_dir = original_dataset_dir + '/test/no_damage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3847ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training damage images:  5000\n",
      "total validation damage images:  1000\n",
      "total test damage images:  1000\n",
      "total training no damage images:  5000\n",
      "total validation no damage images:  1000\n",
      "total test no damage images:  1000\n"
     ]
    }
   ],
   "source": [
    "print('total training damage images: ',len(os.listdir(train_damage_dir)))\n",
    "print('total validation damage images: ',len(os.listdir(validation_damage_dir)))\n",
    "print('total test damage images: ',len(os.listdir(test_damage_dir)))\n",
    "\n",
    "print('total training no damage images: ',len(os.listdir(train_nodamage_dir)))\n",
    "print('total validation no damage images: ',len(os.listdir(validation_nodamage_dir)))\n",
    "print('total test no damage images: ',len(os.listdir(test_nodamage_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour entrainer les modeles\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, steps_per_epoch, validation_steps):\n",
    "    for epoch in range(epochs):\n",
    "        accuracy = 0.0\n",
    "        running_loss = 0.0\n",
    "        # Entraîne le modèle sur les données d'entraînement\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Entraîne le modèle sur un lot de données\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.float().view(-1,1))\n",
    "            loss_values.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #running_loss += loss.item()\n",
    "            accuracy += (torch.round(outputs) == labels.float().view(-1,1)).sum().item() / len(labels)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            if (i+1) % steps_per_epoch == 0:\n",
    "                break\n",
    "        train_loss = running_loss / steps_per_epoch\n",
    "        train_acc = accuracy / steps_per_epoch \n",
    "                \n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_acc = 0\n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels.float().view(-1,1)).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_acc += (torch.round(outputs) == labels.float().view(-1,1)).sum().item() / len(labels)\n",
    "                \n",
    "                if i >= validation_steps:\n",
    "                    break\n",
    "        \n",
    "        val_loss /= validation_steps\n",
    "        val_acc /= validation_steps \n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1eced00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, (3,3))\n",
    "        self.pool1 = nn.MaxPool2d((2,2))\n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,3))\n",
    "        self.pool2 = nn.MaxPool2d((2,2))\n",
    "        self.conv3 = nn.Conv2d(64, 128, (3,3))\n",
    "        self.pool3 = nn.MaxPool2d((2,2))\n",
    "        self.conv4 = nn.Conv2d(128, 128, (3,3))\n",
    "        self.pool4 = nn.MaxPool2d((2,2))\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ac90d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b637e282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 148, 148]             896\n",
      "         MaxPool2d-2           [-1, 32, 74, 74]               0\n",
      "            Conv2d-3           [-1, 64, 72, 72]          18,496\n",
      "         MaxPool2d-4           [-1, 64, 36, 36]               0\n",
      "            Conv2d-5          [-1, 128, 34, 34]          73,856\n",
      "         MaxPool2d-6          [-1, 128, 17, 17]               0\n",
      "            Conv2d-7          [-1, 128, 15, 15]         147,584\n",
      "         MaxPool2d-8            [-1, 128, 7, 7]               0\n",
      "            Linear-9                  [-1, 512]       3,211,776\n",
      "           Linear-10                    [-1, 1]             513\n",
      "================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 11.53\n",
      "Params size (MB): 13.17\n",
      "Estimated Total Size (MB): 24.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "model = CNN()\n",
    "torchsummary.summary(model, (3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efe61c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a419d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    #transforms.Normalize((0,), (1/255,))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder('C:/Users/pauli/Documents/M2/ML et DL/projet/Git/DamageDetection/train_another', transform=train_datagen)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "validation_datagen = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    #transforms.Normalize((0,), (1/255,))\n",
    "])\n",
    "\n",
    "val_dataset = ImageFolder('C:/Users/pauli/Documents/M2/ML et DL/projet/Git/DamageDetection/validation_another', transform=validation_datagen)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c09d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "print('Found {} images belonging to {} classes.'.format(len(train_dataset), len(train_dataset.classes)))\n",
    "print('Found {} images belonging to {} classes.'.format(len(val_dataset), len(val_dataset.classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43792956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.3465, Train Accuracy: 0.6880, Validation Loss: 0.5962, Validation Accuracy: 0.7150\n",
      "Epoch [2/50], Train Loss: 0.2742, Train Accuracy: 0.8495, Validation Loss: 0.3180, Validation Accuracy: 0.9050\n",
      "Epoch [3/50], Train Loss: 0.3879, Train Accuracy: 0.8660, Validation Loss: 0.2508, Validation Accuracy: 0.9220\n",
      "Epoch [4/50], Train Loss: 0.1956, Train Accuracy: 0.8835, Validation Loss: 0.2429, Validation Accuracy: 0.9130\n",
      "Epoch [5/50], Train Loss: 0.6793, Train Accuracy: 0.8970, Validation Loss: 0.2817, Validation Accuracy: 0.9100\n",
      "Epoch [6/50], Train Loss: 0.1135, Train Accuracy: 0.9020, Validation Loss: 0.2132, Validation Accuracy: 0.9420\n",
      "Epoch [7/50], Train Loss: 0.1039, Train Accuracy: 0.9090, Validation Loss: 0.2694, Validation Accuracy: 0.9040\n",
      "Epoch [8/50], Train Loss: 0.2670, Train Accuracy: 0.9110, Validation Loss: 0.2113, Validation Accuracy: 0.9420\n",
      "Epoch [9/50], Train Loss: 0.2011, Train Accuracy: 0.9170, Validation Loss: 0.2035, Validation Accuracy: 0.9410\n",
      "Epoch [10/50], Train Loss: 0.2041, Train Accuracy: 0.9150, Validation Loss: 0.2003, Validation Accuracy: 0.9360\n",
      "Epoch [11/50], Train Loss: 0.1002, Train Accuracy: 0.9250, Validation Loss: 0.2055, Validation Accuracy: 0.9450\n",
      "Epoch [12/50], Train Loss: 0.0737, Train Accuracy: 0.9245, Validation Loss: 0.1879, Validation Accuracy: 0.9510\n",
      "Epoch [13/50], Train Loss: 0.1444, Train Accuracy: 0.9230, Validation Loss: 0.1796, Validation Accuracy: 0.9520\n",
      "Epoch [14/50], Train Loss: 0.1520, Train Accuracy: 0.9330, Validation Loss: 0.1630, Validation Accuracy: 0.9580\n",
      "Epoch [15/50], Train Loss: 0.0799, Train Accuracy: 0.9325, Validation Loss: 0.1756, Validation Accuracy: 0.9460\n",
      "Epoch [16/50], Train Loss: 0.1179, Train Accuracy: 0.9310, Validation Loss: 0.1534, Validation Accuracy: 0.9640\n",
      "Epoch [17/50], Train Loss: 0.3018, Train Accuracy: 0.9300, Validation Loss: 0.1745, Validation Accuracy: 0.9510\n",
      "Epoch [18/50], Train Loss: 0.0870, Train Accuracy: 0.9270, Validation Loss: 0.1457, Validation Accuracy: 0.9630\n",
      "Epoch [19/50], Train Loss: 0.0389, Train Accuracy: 0.9450, Validation Loss: 0.1590, Validation Accuracy: 0.9590\n",
      "Epoch [20/50], Train Loss: 0.1974, Train Accuracy: 0.9355, Validation Loss: 0.1295, Validation Accuracy: 0.9710\n",
      "Epoch [21/50], Train Loss: 0.1116, Train Accuracy: 0.9420, Validation Loss: 0.2022, Validation Accuracy: 0.9470\n",
      "Epoch [22/50], Train Loss: 0.1503, Train Accuracy: 0.9345, Validation Loss: 0.1792, Validation Accuracy: 0.9540\n",
      "Epoch [23/50], Train Loss: 0.1141, Train Accuracy: 0.9345, Validation Loss: 0.1489, Validation Accuracy: 0.9620\n",
      "Epoch [24/50], Train Loss: 0.0919, Train Accuracy: 0.9525, Validation Loss: 0.1729, Validation Accuracy: 0.9510\n",
      "Epoch [25/50], Train Loss: 0.0651, Train Accuracy: 0.9490, Validation Loss: 0.1862, Validation Accuracy: 0.9450\n",
      "Epoch [26/50], Train Loss: 0.4054, Train Accuracy: 0.9450, Validation Loss: 0.1665, Validation Accuracy: 0.9640\n",
      "Epoch [27/50], Train Loss: 0.2890, Train Accuracy: 0.9525, Validation Loss: 0.1329, Validation Accuracy: 0.9800\n",
      "Epoch [28/50], Train Loss: 0.1351, Train Accuracy: 0.9535, Validation Loss: 0.1805, Validation Accuracy: 0.9460\n",
      "Epoch [29/50], Train Loss: 0.0348, Train Accuracy: 0.9510, Validation Loss: 0.1200, Validation Accuracy: 0.9720\n",
      "Epoch [30/50], Train Loss: 0.0602, Train Accuracy: 0.9580, Validation Loss: 0.1107, Validation Accuracy: 0.9750\n",
      "Epoch [31/50], Train Loss: 0.0210, Train Accuracy: 0.9550, Validation Loss: 0.1230, Validation Accuracy: 0.9720\n",
      "Epoch [32/50], Train Loss: 0.0692, Train Accuracy: 0.9580, Validation Loss: 0.1452, Validation Accuracy: 0.9650\n",
      "Epoch [33/50], Train Loss: 0.0041, Train Accuracy: 0.9585, Validation Loss: 0.1227, Validation Accuracy: 0.9740\n",
      "Epoch [34/50], Train Loss: 0.3231, Train Accuracy: 0.9605, Validation Loss: 0.1340, Validation Accuracy: 0.9710\n",
      "Epoch [35/50], Train Loss: 0.2432, Train Accuracy: 0.9620, Validation Loss: 0.1566, Validation Accuracy: 0.9570\n",
      "Epoch [36/50], Train Loss: 0.0479, Train Accuracy: 0.9540, Validation Loss: 0.2311, Validation Accuracy: 0.9800\n",
      "Epoch [37/50], Train Loss: 0.1159, Train Accuracy: 0.9600, Validation Loss: 0.1249, Validation Accuracy: 0.9740\n",
      "Epoch [38/50], Train Loss: 0.1462, Train Accuracy: 0.9605, Validation Loss: 0.1142, Validation Accuracy: 0.9800\n",
      "Epoch [39/50], Train Loss: 0.0270, Train Accuracy: 0.9585, Validation Loss: 0.1382, Validation Accuracy: 0.9640\n",
      "Epoch [40/50], Train Loss: 0.1745, Train Accuracy: 0.9635, Validation Loss: 0.1478, Validation Accuracy: 0.9660\n",
      "Epoch [41/50], Train Loss: 0.1203, Train Accuracy: 0.9620, Validation Loss: 0.1093, Validation Accuracy: 0.9840\n",
      "Epoch [42/50], Train Loss: 0.0416, Train Accuracy: 0.9620, Validation Loss: 0.2001, Validation Accuracy: 0.9810\n",
      "Epoch [43/50], Train Loss: 0.2404, Train Accuracy: 0.9615, Validation Loss: 0.1887, Validation Accuracy: 0.9920\n",
      "Epoch [44/50], Train Loss: 0.1911, Train Accuracy: 0.9695, Validation Loss: 0.1170, Validation Accuracy: 0.9800\n",
      "Epoch [45/50], Train Loss: 0.0386, Train Accuracy: 0.9720, Validation Loss: 0.1081, Validation Accuracy: 0.9790\n",
      "Epoch [46/50], Train Loss: 0.1027, Train Accuracy: 0.9680, Validation Loss: 0.0969, Validation Accuracy: 0.9880\n",
      "Epoch [47/50], Train Loss: 0.0722, Train Accuracy: 0.9705, Validation Loss: 0.1672, Validation Accuracy: 0.9930\n",
      "Epoch [48/50], Train Loss: 0.0078, Train Accuracy: 0.9680, Validation Loss: 0.0810, Validation Accuracy: 0.9880\n",
      "Epoch [49/50], Train Loss: 0.0238, Train Accuracy: 0.9720, Validation Loss: 0.1040, Validation Accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialisation des paramètres \n",
    "steps_per_epoch = 100\n",
    "epochs = 50\n",
    "validation_steps = 50\n",
    "\n",
    "# Lancer l'entraînement\n",
    "fit(model, train_loader, val_loader, epochs, steps_per_epoch, validation_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
