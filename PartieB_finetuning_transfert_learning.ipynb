{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466d273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5a78b",
   "metadata": {},
   "source": [
    "## Transformer le modèle keras h5 en pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bea171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreer un modele pytorch pour stocker notre modèle keras dedans\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)  \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, h):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, h)\n",
    "        self.fc2 = nn.Linear(h, h)\n",
    "        self.fc3 = nn.Linear(h, h)\n",
    "        self.fc4 = nn.Linear(h, h)\n",
    "        self.fc5 = nn.Linear(h, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "        self.fc4.weight.data.uniform_(*hidden_init(self.fc4))\n",
    "        self.fc5.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        return F.tanh(self.fc5(x))\n",
    "\n",
    "net=Actor(1,1,time.time(),32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c759ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On charge le modele\n",
    "model = load_model('tomnod_everything_relu_Adam.h5')\n",
    "\n",
    "#On recupere ses poids\n",
    "weights=model.get_weights()\n",
    "\n",
    "#On transpose les poids dans le modèle pytorch\n",
    "net.fc1.weight.data=torch.from_numpy(np.transpose(weights[0]))\n",
    "net.fc1.bias.data=torch.from_numpy(weights[1])\n",
    "net.fc2.weight.data=torch.from_numpy(np.transpose(weights[2]))\n",
    "net.fc2.bias.data=torch.from_numpy(weights[3])\n",
    "net.fc3.weight.data=torch.from_numpy(np.transpose(weights[4]))\n",
    "net.fc3.bias.data=torch.from_numpy(weights[5])\n",
    "net.fc4.weight.data=torch.from_numpy(np.transpose(weights[6]))\n",
    "net.fc4.bias.data=torch.from_numpy(weights[7])\n",
    "net.fc5.weight.data=torch.from_numpy(np.transpose(weights[8]))\n",
    "net.fc5.bias.data=torch.from_numpy(weights[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "259ebf2b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m x\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(entries,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\n\u001b[0;32m      4\u001b[0m y\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msin(x)\u001b[38;5;241m+\u001b[39m(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(entries,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.1\u001b[39m)  \n\u001b[1;32m----> 5\u001b[0m xReal\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mentries\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m xReal\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray([xReal]))\n\u001b[0;32m      7\u001b[0m yReal\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msin(xReal) \n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLDL\\lib\\site-packages\\numpy\\core\\function_base.py:121\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_linspace_dispatcher)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinspace\u001b[39m(start, stop, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retstep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m              axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Return evenly spaced numbers over a specified interval.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m \n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     num \u001b[38;5;241m=\u001b[39m \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of samples, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, must be non-negative.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m num)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#Faux data set pour tester\n",
    "entries=10000\n",
    "x=np.random.randn(entries,1)*np.pi\n",
    "y=np.sin(x)+(np.random.randn(entries,1)*.1)  \n",
    "xReal=np.linspace(-np.pi*3,np.pi*3,entries/100)\n",
    "xReal=np.transpose(np.array([xReal]))\n",
    "yReal=np.sin(xReal) \n",
    "\n",
    "pyPredict0=net.forward(torch.from_numpy(xReal).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d946b1",
   "metadata": {},
   "source": [
    "## Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a83ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour geler toutes les couches sauf la dernière \n",
    "\n",
    "for param in model.parameters():  \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6de30672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcdf0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Definir la fonction de transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Définir le jeu de données d'entraînement (par exemple CIFAR10)\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform) \n",
    "\n",
    "# Définir le DataLoader pour les données d'entraînement\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                          shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5062997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger un modèle pré-entraîné (ici ResNet18)\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Définir la dernière couche en fonction du nombre de classes dans votre jeu de données\n",
    "num_classes = 10 # nombre de classes\n",
    "model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "# Définir les paramètres à optimiser\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        \n",
    "# Configurer l'optimiseur (SGD avec une faible vitesse d'apprentissage)\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# Définir la fonction de perte (cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Définir les épochs \n",
    "num_epochs = 50 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.3f' %\n",
    "          (epoch + 1, i + 1, running_loss / (i + 1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
