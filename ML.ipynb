{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f8027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch functions\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torchvision functions\n",
    "import torchvision\n",
    "from torchvision.models import vgg16\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# import other functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "from itertools import islice\n",
    "from PIL import Image\n",
    "import time \n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d57285",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = r'C:\\Users\\pattal\\Documents\\DamageDetection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907b809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_damage_dir = original_dataset_dir + '/train_another/damage'\n",
    "validation_damage_dir = original_dataset_dir + '/validation_another/damage'\n",
    "test_damage_dir = original_dataset_dir + '/test/damage'\n",
    "\n",
    "train_nodamage_dir = original_dataset_dir + '/train_another/no_damage'\n",
    "validation_nodamage_dir = original_dataset_dir + '/validation_another/no_damage'\n",
    "test_nodamage_dir = original_dataset_dir + '/test/no_damage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3847ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training damage images:  5000\n",
      "total validation damage images:  1000\n",
      "total test damage images:  1000\n",
      "total training no damage images:  5000\n",
      "total validation no damage images:  1000\n",
      "total test no damage images:  1000\n"
     ]
    }
   ],
   "source": [
    "print('total training damage images: ',len(os.listdir(train_damage_dir)))\n",
    "print('total validation damage images: ',len(os.listdir(validation_damage_dir)))\n",
    "print('total test damage images: ',len(os.listdir(test_damage_dir)))\n",
    "\n",
    "print('total training no damage images: ',len(os.listdir(train_nodamage_dir)))\n",
    "print('total validation no damage images: ',len(os.listdir(validation_nodamage_dir)))\n",
    "print('total test no damage images: ',len(os.listdir(test_nodamage_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe3aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour entrainer les modeles\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, steps_per_epoch, validation_steps):\n",
    "    epoch_nums = []\n",
    "    training_acc = []\n",
    "    validation_acc = []\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        accuracy = 0.0\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        # Entraîne le modèle sur les données d'entraînement\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Entraîne le modèle sur un lot de données\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.float().view(-1,1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #running_loss += loss.item()\n",
    "            accuracy += (torch.round(outputs) == labels.float().view(-1,1)).sum().item() / len(labels)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            if (i+1) % steps_per_epoch == 0:\n",
    "                break\n",
    "        train_loss = running_loss / steps_per_epoch\n",
    "        train_acc = accuracy / steps_per_epoch \n",
    "                \n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_acc = 0\n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels.float().view(-1,1)).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_acc += (torch.round(outputs) == labels.float().view(-1,1)).sum().item() / len(labels)\n",
    "                \n",
    "                if i >= validation_steps:\n",
    "                    break\n",
    "        \n",
    "        val_loss /= validation_steps\n",
    "        val_acc /= validation_steps \n",
    "\n",
    "        epoch_nums.append(epoch+1)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(val_loss)\n",
    "        training_acc.append(train_acc)\n",
    "        validation_acc.append(val_acc)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(elapsed_time)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Time : {elapsed_time:.4f}, Train Loss: {loss.item():.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "    return {\n",
    "        'training_acc': training_acc,\n",
    "        'validation_acc': validation_acc,\n",
    "        'training_loss': training_loss,\n",
    "        'validation_loss': validation_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f094b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-17          [-1, 256, 18, 18]               0\n",
      "           Conv2d-18          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-19          [-1, 512, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-24            [-1, 512, 9, 9]               0\n",
      "           Conv2d-25            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-26            [-1, 512, 9, 9]               0\n",
      "           Conv2d-27            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "        MaxPool2d-31            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 96.93\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 624.98\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-17          [-1, 256, 18, 18]               0\n",
      "           Conv2d-18          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-19          [-1, 512, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-24            [-1, 512, 9, 9]               0\n",
      "           Conv2d-25            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-26            [-1, 512, 9, 9]               0\n",
      "           Conv2d-27            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 96.49\n",
      "Params size (MB): 56.13\n",
      "Estimated Total Size (MB): 152.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Chargment du modèle pré-entraîné ResNet18\n",
    "modelvgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "torchsummary.summary(modelvgg16, (3,150,150))\n",
    "\n",
    "# Extraction des caractéristiques\n",
    "modelvgg16 = modelvgg16.features[:-1] # nombre de caractéristiques en entrée de la couche fc\n",
    "torchsummary.summary(modelvgg16, (3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd23638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    #transforms.Normalize((0,), (1/255,))\n",
    "])\n",
    "\n",
    "batch_size=20\n",
    "\n",
    "train_dataset = ImageFolder(r'C:\\Users\\pattal\\Documents\\DamageDetection\\train_another', transform=datagen)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "val_dataset = ImageFolder(r'C:\\Users\\pattal\\Documents\\DamageDetection\\validation_another', transform=datagen)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder(r'C:\\Users\\pattal\\Documents\\DamageDetection\\test_another', transform=datagen)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "\n",
    "modelvgg16.eval()\n",
    "\n",
    "# Extraire les caractéristiques des images\n",
    "def extract_features(data_loader, sample_count, conv_base, batch_size):\n",
    "    features = torch.zeros(sample_count, 512, 9, 9)\n",
    "    labels = torch.zeros(sample_count, dtype=torch.long)\n",
    "    \n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in data_loader:\n",
    "        with torch.no_grad():\n",
    "            features_batch = conv_base(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61f00c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features(train_loader, 10000, modelvgg16, batch_size=batch_size)\n",
    "validation_features, validation_labels = extract_features(val_loader, 2000, modelvgg16, batch_size=batch_size)\n",
    "test_features, test_labels = extract_features(test_loader, 2000, modelvgg16, batch_size=batch_size)\n",
    "\n",
    "# Reformater les caractéristiques pour être de forme (sample_count, 8192)\n",
    "train_features = train_features.view(10000, 9 * 9 * 512)\n",
    "validation_features = validation_features.view(2000, 9 * 9 * 512)\n",
    "test_features = test_features.view(2000, 9 * 9 * 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0f08943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BinaryClassifier, train_features, train_labels, val_features, validation_labels, num_epochs, batch_size):\n",
    "    train_features = train_features.float()\n",
    "    train_labels = train_labels.long()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_features)\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Valider le modèle\n",
    "        with torch.no_grad():\n",
    "            validation_outputs = model(validation_features.float())\n",
    "            _, validation_predicted = torch.max(validation_outputs, 1)\n",
    "            validation_correct = (validation_predicted == validation_labels.long()).sum().item()\n",
    "            validation_accuracy = validation_correct / validation_labels.shape[0]\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, Validation Accuracy: {:.2f}%'.format(epoch + 1, num_epochs, loss.item(), validation_accuracy * 100))\n",
    "        \n",
    "        \n",
    "def evaluate(model, test_feature, test_labels):\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_features.float())\n",
    "        _, test_predicted = torch.max(test_outputs, 1)\n",
    "        test_correct = (test_predicted == test_labels.long()).sum().item()\n",
    "        test_accuracy = test_correct / test_labels.shape[0]\n",
    "        print('Test Accuracy: {:.2f}%'.format(test_accuracy * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f910eea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10000x41472 and 8192x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mRMSprop(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBinaryClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#BinaryClassifier.evaluate(test_features,test_labels)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(BinaryClassifier, train_features, train_labels, val_features, validation_labels, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, train_labels)\n\u001b[0;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m, in \u001b[0;36mBinaryClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10000x41472 and 8192x256)"
     ]
    }
   ],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(4*4*512, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "BinaryClassifier = BinaryClassifier()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "\n",
    "train(BinaryClassifier, train_features, train_labels, validation_features, validation_labels, 10, 20)\n",
    "\n",
    "#BinaryClassifier.evaluate(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4707c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des paramètres \n",
    "steps_per_epoch = 100\n",
    "epochs = 30\n",
    "validation_steps = 50\n",
    "\n",
    "# Lancer l'entraînement\n",
    "history = fit(BinaryClassifier, train_features, validation_features, epochs, steps_per_epoch, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44091787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6faf59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b27c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a906a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pattal\\.conda\\envs\\DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc =  0.9365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression(C = 1)\n",
    "logisticRegr.fit(train_features,train_labels)\n",
    "#balanced test set \n",
    "score1 = logisticRegr.score(validation_features, validation_labels)\n",
    "print(\"Validation acc = \", score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b1a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a72cdb8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Évaluation du modèle\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 6\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m model_load(\u001b[43mtest_features\u001b[49m)\n\u001b[0;32m      7\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()(test_outputs, test_labels)\n\u001b[0;32m      8\u001b[0m     test_results \u001b[38;5;241m=\u001b[39m (test_loss, test_outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39meq(test_labels)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Chargement du modèle\n",
    "model_load = model\n",
    "\n",
    "# Évaluation du modèle\n",
    "with torch.no_grad():\n",
    "    test_outputs = model_load(test_features)\n",
    "    test_loss = nn.BCELoss()(test_outputs, test_labels)\n",
    "    test_results = (test_loss, test_outputs.argmax(dim=1).eq(test_labels).float().mean().item())\n",
    "    print(test_results)\n",
    "\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size, C=1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e423be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe1de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31a365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
